{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ok9xpaI-uyUT"
   },
   "source": [
    "![sutd](imgs/sutd.png)\n",
    "## <center>50.040 Natural Language Processing, Summer 2019<center>\n",
    "<center>**Homework 2**\n",
    "\n",
    "<center>**Due 5 July 2019, 5pm** <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WHLjIQokuyUV"
   },
   "source": [
    "**Write your student ID and name**\n",
    "\n",
    "ID: 1002323\n",
    "\n",
    "Name: Woong Wen Tat\n",
    "\n",
    "Students with whom you have discussed (if any):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F7rJYYMnuyUW"
   },
   "source": [
    "### Requirements:\n",
    "- Use Python to complete this homework.\n",
    "- Please list students with whom you have discussed (if any).\n",
    "- Follow the honor code strictly.\n",
    "- Submit this ipynb file on eDimension before the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8OQF8DZuyUY"
   },
   "source": [
    "## Introduction\n",
    "Constituency parsing aims to extract a constituency-based parse tree from a sentence that represents its syntactic structure according to a phrase structure grammar.\n",
    "\n",
    "A typical constituency parse tree is shown below:\n",
    "\n",
    "![tree](imgs/parse_tree.png)\n",
    "\n",
    "$S$ is a distinguished start symbol, node labels such as $NP$(noun phrase), $VP$(verb phrase) are non-terminal symbols, leaf labels such as \"a\", \"banana\" are terminal symbols.\n",
    "\n",
    "In this homework, we will be implementing a constituency parser based on probabilistic context-free grammars (PCFGs) and evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uhWbyjQMuyUZ"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "We will be using a version of the [Penn Treebank](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.9.8216&rep=rep1&type=pdf) released in [NLTK corpora](http://www.nltk.org/nltk_data/) to induce PCFGs and evaluate our algorithm. \n",
    "\n",
    "The preprocessing code has been provided, **do not make any changes to the texts and code unless you are requested to do so.** Run the code below to load the training and test sets as Python lists, it will take ~1 minute.\n",
    "\n",
    "Since we will not be tuning hyper-parameters for this homework, there will be no need for a development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K3VThG6AuyUZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\Lumo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJ_WLuC7uyUb"
   },
   "outputs": [],
   "source": [
    "from util import get_train_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8V8JI2gfuyUe"
   },
   "outputs": [],
   "source": [
    "#cnf_trees_train: training set, a list of parse trees\n",
    "#cnf_trees_test: test set, a list of parse trees\n",
    "cnf_trees_train, cnf_trees_test = get_train_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zpy9gpyLuyUh"
   },
   "source": [
    "Each parse tree is of the [nltk.tree.Tree](https://www.nltk.org/_modules/nltk/tree.html) type and has been converted to the Chomsky normal form. Let us look at a sample parse tree in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UY1_rx5GuyUi",
    "outputId": "d6227980-6126-4ae1-e5c6-a9b43d4d4eb2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP\n",
      "    (NP (NNP pierre) (NNP vinken))\n",
      "    (NP (, ,) (NP (ADJP (NP (CD 61) (NNS years)) (JJ old)) (, ,))))\n",
      "  (S\n",
      "    (VP\n",
      "      (MD will)\n",
      "      (VP\n",
      "        (VB join)\n",
      "        (VP\n",
      "          (NP (DT the) (NN board))\n",
      "          (VP\n",
      "            (PP\n",
      "              (IN as)\n",
      "              (NP (DT a) (NP (JJ nonexecutive) (NN director))))\n",
      "            (NP (NNP nov.) (CD 29))))))\n",
      "    (. .)))\n"
     ]
    }
   ],
   "source": [
    "print(cnf_trees_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nWc7JMXduyUm"
   },
   "source": [
    "## PCFG\n",
    "\n",
    "A probabilistic context-free grammar consists of:\n",
    "- A context-free grammar $G=(N, \\ \\Sigma, \\ S, \\ R)$ where $N$ is a finite set of non-terminal symbols, $\\Sigma$ is a finite set of terminal symbols, $R$ is a finite set of rules (e.g., $NP \\rightarrow NP \\ PP$), $S \\in N$ is the start symbol.\n",
    "- One parameter $q(A \\rightarrow \\beta)$ for each rule $A \\rightarrow \\beta$ in $R$. Since the grammar is in Chomsky normal form, there are only two types of rules: $A \\rightarrow B \\ C$ and $A \\rightarrow \\alpha$, where $A$, $B$, $C \\in N$, $\\alpha \\in \\Sigma$.\n",
    "\n",
    "We can estimate the parameter $q(A \\rightarrow \\beta)$ using maximum likelihood estimation:\n",
    "\n",
    "$$q_{MLE}(A \\rightarrow \\beta) = \\frac {count(A \\rightarrow \\beta)}{count(A)}$$\n",
    "where $count(A \\rightarrow \\beta)$ refers to the number of times we can observe the rule $A \\rightarrow \\beta$ in all the parse trees in the training set, and  $count(A)$  refers to the number of times we can see the non-terminal symbol $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cIOrq0lXuyUm"
   },
   "source": [
    "### Task 1 (6 points)\n",
    "\n",
    "Starting from a single parse tree:\n",
    "- First of all, let us only consider the first parse tree in the training set. List down all the unique grammar rules, unique non-terminal symbols, and unique terminal symbols that appear in this first parse tree from the training set.\n",
    "\n",
    "Hint: [nltk.tree.Tree](https://www.nltk.org/_modules/nltk/tree.html) class provides many methods to get features of a tree. **Don't make any changes to the trees.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xiS4m4oMuyUn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Tree in module nltk.tree object:\n",
      "\n",
      "class Tree(builtins.list)\n",
      " |  A Tree represents a hierarchical grouping of leaves and subtrees.\n",
      " |  For example, each constituent in a syntax tree is represented by a single Tree.\n",
      " |  \n",
      " |  A tree's children are encoded as a list of leaves and subtrees,\n",
      " |  where a leaf is a basic (non-tree) value; and a subtree is a\n",
      " |  nested Tree.\n",
      " |  \n",
      " |      >>> from nltk.tree import Tree\n",
      " |      >>> print(Tree(1, [2, Tree(3, [4]), 5]))\n",
      " |      (1 2 (3 4) 5)\n",
      " |      >>> vp = Tree('VP', [Tree('V', ['saw']),\n",
      " |      ...                  Tree('NP', ['him'])])\n",
      " |      >>> s = Tree('S', [Tree('NP', ['I']), vp])\n",
      " |      >>> print(s)\n",
      " |      (S (NP I) (VP (V saw) (NP him)))\n",
      " |      >>> print(s[1])\n",
      " |      (VP (V saw) (NP him))\n",
      " |      >>> print(s[1,1])\n",
      " |      (NP him)\n",
      " |      >>> t = Tree.fromstring(\"(S (NP I) (VP (V saw) (NP him)))\")\n",
      " |      >>> s == t\n",
      " |      True\n",
      " |      >>> t[1][1].set_label('X')\n",
      " |      >>> t[1][1].label()\n",
      " |      'X'\n",
      " |      >>> print(t)\n",
      " |      (S (NP I) (VP (V saw) (X him)))\n",
      " |      >>> t[0], t[1,1] = t[1,1], t[0]\n",
      " |      >>> print(t)\n",
      " |      (S (X him) (VP (V saw) (NP I)))\n",
      " |  \n",
      " |  The length of a tree is the number of children it has.\n",
      " |  \n",
      " |      >>> len(t)\n",
      " |      2\n",
      " |  \n",
      " |  The set_label() and label() methods allow individual constituents\n",
      " |  to be labeled.  For example, syntax trees use this label to specify\n",
      " |  phrase tags, such as \"NP\" and \"VP\".\n",
      " |  \n",
      " |  Several Tree methods use \"tree positions\" to specify\n",
      " |  children or descendants of a tree.  Tree positions are defined as\n",
      " |  follows:\n",
      " |  \n",
      " |    - The tree position *i* specifies a Tree's *i*\\ th child.\n",
      " |    - The tree position ``()`` specifies the Tree itself.\n",
      " |    - If *p* is the tree position of descendant *d*, then\n",
      " |      *p+i* specifies the *i*\\ th child of *d*.\n",
      " |  \n",
      " |  I.e., every tree position is either a single index *i*,\n",
      " |  specifying ``tree[i]``; or a sequence *i1, i2, ..., iN*,\n",
      " |  specifying ``tree[i1][i2]...[iN]``.\n",
      " |  \n",
      " |  Construct a new tree.  This constructor can be called in one\n",
      " |  of two ways:\n",
      " |  \n",
      " |  - ``Tree(label, children)`` constructs a new tree with the\n",
      " |      specified label and list of children.\n",
      " |  \n",
      " |  - ``Tree.fromstring(s)`` constructs a new tree by parsing the string ``s``.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Tree\n",
      " |      builtins.list\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, v)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __delitem__(self, index)\n",
      " |      Delete self[key].\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__ lambda self, other\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __gt__ lambda self, other\n",
      " |  \n",
      " |  __init__(self, node, children=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __le__ lambda self, other\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mul__(self, v)\n",
      " |      Return self*value.n\n",
      " |  \n",
      " |  __ne__ lambda self, other\n",
      " |      # @total_ordering doesn't work here, since the class inherits from a builtin class\n",
      " |  \n",
      " |  __radd__(self, v)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rmul__(self, v)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __setitem__(self, index, value)\n",
      " |      Set self[key] to value.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __unicode__ = __str__(self)\n",
      " |  \n",
      " |  chomsky_normal_form(self, factor='right', horzMarkov=None, vertMarkov=0, childChar='|', parentChar='^')\n",
      " |      This method can modify a tree in three ways:\n",
      " |      \n",
      " |        1. Convert a tree into its Chomsky Normal Form (CNF)\n",
      " |           equivalent -- Every subtree has either two non-terminals\n",
      " |           or one terminal as its children.  This process requires\n",
      " |           the creation of more\"artificial\" non-terminal nodes.\n",
      " |        2. Markov (vertical) smoothing of children in new artificial\n",
      " |           nodes\n",
      " |        3. Horizontal (parent) annotation of nodes\n",
      " |      \n",
      " |      :param factor: Right or left factoring method (default = \"right\")\n",
      " |      :type  factor: str = [left|right]\n",
      " |      :param horzMarkov: Markov order for sibling smoothing in artificial nodes (None (default) = include all siblings)\n",
      " |      :type  horzMarkov: int | None\n",
      " |      :param vertMarkov: Markov order for parent smoothing (0 (default) = no vertical annotation)\n",
      " |      :type  vertMarkov: int | None\n",
      " |      :param childChar: A string used in construction of the artificial nodes, separating the head of the\n",
      " |                        original subtree from the child nodes that have yet to be expanded (default = \"|\")\n",
      " |      :type  childChar: str\n",
      " |      :param parentChar: A string used to separate the node representation from its vertical annotation\n",
      " |      :type  parentChar: str\n",
      " |  \n",
      " |  collapse_unary(self, collapsePOS=False, collapseRoot=False, joinChar='+')\n",
      " |      Collapse subtrees with a single child (ie. unary productions)\n",
      " |      into a new non-terminal (Tree node) joined by 'joinChar'.\n",
      " |      This is useful when working with algorithms that do not allow\n",
      " |      unary productions, and completely removing the unary productions\n",
      " |      would require loss of useful information.  The Tree is modified\n",
      " |      directly (since it is passed by reference) and no value is returned.\n",
      " |      \n",
      " |      :param collapsePOS: 'False' (default) will not collapse the parent of leaf nodes (ie.\n",
      " |                          Part-of-Speech tags) since they are always unary productions\n",
      " |      :type  collapsePOS: bool\n",
      " |      :param collapseRoot: 'False' (default) will not modify the root production\n",
      " |                           if it is unary.  For the Penn WSJ treebank corpus, this corresponds\n",
      " |                           to the TOP -> productions.\n",
      " |      :type collapseRoot: bool\n",
      " |      :param joinChar: A string used to connect collapsed node values (default = \"+\")\n",
      " |      :type  joinChar: str\n",
      " |  \n",
      " |  copy(self, deep=False)\n",
      " |      L.copy() -> list -- a shallow copy of L\n",
      " |  \n",
      " |  draw(self)\n",
      " |      Open a new window containing a graphical diagram of this tree.\n",
      " |  \n",
      " |  flatten(self)\n",
      " |      Return a flat version of the tree, with all non-root non-terminals removed.\n",
      " |      \n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> print(t.flatten())\n",
      " |          (S the dog chased the cat)\n",
      " |      \n",
      " |      :return: a tree consisting of this tree's root connected directly to\n",
      " |          its leaves, omitting all intervening non-terminal nodes.\n",
      " |      :rtype: Tree\n",
      " |  \n",
      " |  freeze(self, leaf_freezer=None)\n",
      " |  \n",
      " |  height(self)\n",
      " |      Return the height of the tree.\n",
      " |      \n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> t.height()\n",
      " |          5\n",
      " |          >>> print(t[0,0])\n",
      " |          (D the)\n",
      " |          >>> t[0,0].height()\n",
      " |          2\n",
      " |      \n",
      " |      :return: The height of this tree.  The height of a tree\n",
      " |          containing no children is 1; the height of a tree\n",
      " |          containing only leaves is 2; and the height of any other\n",
      " |          tree is one plus the maximum of its children's\n",
      " |          heights.\n",
      " |      :rtype: int\n",
      " |  \n",
      " |  label(self)\n",
      " |      Return the node label of the tree.\n",
      " |      \n",
      " |          >>> t = Tree.fromstring('(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))')\n",
      " |          >>> t.label()\n",
      " |          'S'\n",
      " |      \n",
      " |      :return: the node label (typically a string)\n",
      " |      :rtype: any\n",
      " |  \n",
      " |  leaf_treeposition(self, index)\n",
      " |      :return: The tree position of the ``index``-th leaf in this\n",
      " |          tree.  I.e., if ``tp=self.leaf_treeposition(i)``, then\n",
      " |          ``self[tp]==self.leaves()[i]``.\n",
      " |      \n",
      " |      :raise IndexError: If this tree contains fewer than ``index+1``\n",
      " |          leaves, or if ``index<0``.\n",
      " |  \n",
      " |  leaves(self)\n",
      " |      Return the leaves of the tree.\n",
      " |      \n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> t.leaves()\n",
      " |          ['the', 'dog', 'chased', 'the', 'cat']\n",
      " |      \n",
      " |      :return: a list containing this tree's leaves.\n",
      " |          The order reflects the order of the\n",
      " |          leaves in the tree's hierarchical structure.\n",
      " |      :rtype: list\n",
      " |  \n",
      " |  pformat(self, margin=70, indent=0, nodesep='', parens='()', quotes=False)\n",
      " |      :return: A pretty-printed string representation of this tree.\n",
      " |      :rtype: str\n",
      " |      :param margin: The right margin at which to do line-wrapping.\n",
      " |      :type margin: int\n",
      " |      :param indent: The indentation level at which printing\n",
      " |          begins.  This number is used to decide how far to indent\n",
      " |          subsequent lines.\n",
      " |      :type indent: int\n",
      " |      :param nodesep: A string that is used to separate the node\n",
      " |          from the children.  E.g., the default value ``':'`` gives\n",
      " |          trees like ``(S: (NP: I) (VP: (V: saw) (NP: it)))``.\n",
      " |  \n",
      " |  pformat_latex_qtree(self)\n",
      " |      Returns a representation of the tree compatible with the\n",
      " |      LaTeX qtree package. This consists of the string ``\\Tree``\n",
      " |      followed by the tree represented in bracketed notation.\n",
      " |      \n",
      " |      For example, the following result was generated from a parse tree of\n",
      " |      the sentence ``The announcement astounded us``::\n",
      " |      \n",
      " |        \\Tree [.I'' [.N'' [.D The ] [.N' [.N announcement ] ] ]\n",
      " |            [.I' [.V'' [.V' [.V astounded ] [.N'' [.N' [.N us ] ] ] ] ] ] ]\n",
      " |      \n",
      " |      See http://www.ling.upenn.edu/advice/latex.html for the LaTeX\n",
      " |      style file for the qtree package.\n",
      " |      \n",
      " |      :return: A latex qtree representation of this tree.\n",
      " |      :rtype: str\n",
      " |  \n",
      " |  pos(self)\n",
      " |      Return a sequence of pos-tagged words extracted from the tree.\n",
      " |      \n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> t.pos()\n",
      " |          [('the', 'D'), ('dog', 'N'), ('chased', 'V'), ('the', 'D'), ('cat', 'N')]\n",
      " |      \n",
      " |      :return: a list of tuples containing leaves and pre-terminals (part-of-speech tags).\n",
      " |          The order reflects the order of the leaves in the tree's hierarchical structure.\n",
      " |      :rtype: list(tuple)\n",
      " |  \n",
      " |  pprint(self, **kwargs)\n",
      " |      Print a string representation of this Tree to 'stream'\n",
      " |  \n",
      " |  pretty_print(self, sentence=None, highlight=(), stream=None, **kwargs)\n",
      " |      Pretty-print this tree as ASCII or Unicode art.\n",
      " |      For explanation of the arguments, see the documentation for\n",
      " |      `nltk.treeprettyprinter.TreePrettyPrinter`.\n",
      " |  \n",
      " |  productions(self)\n",
      " |      Generate the productions that correspond to the non-terminal nodes of the tree.\n",
      " |      For each subtree of the form (P: C1 C2 ... Cn) this produces a production of the\n",
      " |      form P -> C1 C2 ... Cn.\n",
      " |      \n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> t.productions()\n",
      " |          [S -> NP VP, NP -> D N, D -> 'the', N -> 'dog', VP -> V NP, V -> 'chased',\n",
      " |          NP -> D N, D -> 'the', N -> 'cat']\n",
      " |      \n",
      " |      :rtype: list(Production)\n",
      " |  \n",
      " |  set_label(self, label)\n",
      " |      Set the node label of the tree.\n",
      " |      \n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> t.set_label(\"T\")\n",
      " |          >>> print(t)\n",
      " |          (T (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\n",
      " |      \n",
      " |      :param label: the node label (typically a string)\n",
      " |      :type label: any\n",
      " |  \n",
      " |  subtrees(self, filter=None)\n",
      " |      Generate all the subtrees of this tree, optionally restricted\n",
      " |      to trees matching the filter function.\n",
      " |      \n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> for s in t.subtrees(lambda t: t.height() == 2):\n",
      " |          ...     print(s)\n",
      " |          (D the)\n",
      " |          (N dog)\n",
      " |          (V chased)\n",
      " |          (D the)\n",
      " |          (N cat)\n",
      " |      \n",
      " |      :type filter: function\n",
      " |      :param filter: the function to filter all local trees\n",
      " |  \n",
      " |  treeposition_spanning_leaves(self, start, end)\n",
      " |      :return: The tree position of the lowest descendant of this\n",
      " |          tree that dominates ``self.leaves()[start:end]``.\n",
      " |      :raise ValueError: if ``end <= start``\n",
      " |  \n",
      " |  treepositions(self, order='preorder')\n",
      " |          >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n",
      " |          >>> t.treepositions() # doctest: +ELLIPSIS\n",
      " |          [(), (0,), (0, 0), (0, 0, 0), (0, 1), (0, 1, 0), (1,), (1, 0), (1, 0, 0), ...]\n",
      " |          >>> for pos in t.treepositions('leaves'):\n",
      " |          ...     t[pos] = t[pos][::-1].upper()\n",
      " |          >>> print(t)\n",
      " |          (S (NP (D EHT) (N GOD)) (VP (V DESAHC) (NP (D EHT) (N TAC))))\n",
      " |      \n",
      " |      :param order: One of: ``preorder``, ``postorder``, ``bothorder``,\n",
      " |          ``leaves``.\n",
      " |  \n",
      " |  un_chomsky_normal_form(self, expandUnary=True, childChar='|', parentChar='^', unaryChar='+')\n",
      " |      This method modifies the tree in three ways:\n",
      " |      \n",
      " |        1. Transforms a tree in Chomsky Normal Form back to its\n",
      " |           original structure (branching greater than two)\n",
      " |        2. Removes any parent annotation (if it exists)\n",
      " |        3. (optional) expands unary subtrees (if previously\n",
      " |           collapsed with collapseUnary(...) )\n",
      " |      \n",
      " |      :param expandUnary: Flag to expand unary or not (default = True)\n",
      " |      :type  expandUnary: bool\n",
      " |      :param childChar: A string separating the head node from its children in an artificial node (default = \"|\")\n",
      " |      :type  childChar: str\n",
      " |      :param parentChar: A sting separating the node label from its parent annotation (default = \"^\")\n",
      " |      :type  parentChar: str\n",
      " |      :param unaryChar: A string joining two non-terminals in a unary production (default = \"+\")\n",
      " |      :type  unaryChar: str\n",
      " |  \n",
      " |  unicode_repr = __repr__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  convert(tree) from builtins.type\n",
      " |      Convert a tree between different subtypes of Tree.  ``cls`` determines\n",
      " |      which class will be used to encode the new tree.\n",
      " |      \n",
      " |      :type tree: Tree\n",
      " |      :param tree: The tree that should be converted.\n",
      " |      :return: The new Tree.\n",
      " |  \n",
      " |  fromstring(s, brackets='()', read_node=None, read_leaf=None, node_pattern=None, leaf_pattern=None, remove_empty_top_bracketing=False) from builtins.type\n",
      " |      Read a bracketed tree string and return the resulting tree.\n",
      " |      Trees are represented as nested brackettings, such as::\n",
      " |      \n",
      " |        (S (NP (NNP John)) (VP (V runs)))\n",
      " |      \n",
      " |      :type s: str\n",
      " |      :param s: The string to read\n",
      " |      \n",
      " |      :type brackets: str (length=2)\n",
      " |      :param brackets: The bracket characters used to mark the\n",
      " |          beginning and end of trees and subtrees.\n",
      " |      \n",
      " |      :type read_node: function\n",
      " |      :type read_leaf: function\n",
      " |      :param read_node, read_leaf: If specified, these functions\n",
      " |          are applied to the substrings of ``s`` corresponding to\n",
      " |          nodes and leaves (respectively) to obtain the values for\n",
      " |          those nodes and leaves.  They should have the following\n",
      " |          signature:\n",
      " |      \n",
      " |             read_node(str) -> value\n",
      " |      \n",
      " |          For example, these functions could be used to process nodes\n",
      " |          and leaves whose values should be some type other than\n",
      " |          string (such as ``FeatStruct``).\n",
      " |          Note that by default, node strings and leaf strings are\n",
      " |          delimited by whitespace and brackets; to override this\n",
      " |          default, use the ``node_pattern`` and ``leaf_pattern``\n",
      " |          arguments.\n",
      " |      \n",
      " |      :type node_pattern: str\n",
      " |      :type leaf_pattern: str\n",
      " |      :param node_pattern, leaf_pattern: Regular expression patterns\n",
      " |          used to find node and leaf substrings in ``s``.  By\n",
      " |          default, both nodes patterns are defined to match any\n",
      " |          sequence of non-whitespace non-bracket characters.\n",
      " |      \n",
      " |      :type remove_empty_top_bracketing: bool\n",
      " |      :param remove_empty_top_bracketing: If the resulting tree has\n",
      " |          an empty node label, and is length one, then return its\n",
      " |          single child instead.  This is useful for treebank trees,\n",
      " |          which sometimes contain an extra level of bracketing.\n",
      " |      \n",
      " |      :return: A tree corresponding to the string representation ``s``.\n",
      " |          If this class method is called using a subclass of Tree,\n",
      " |          then it will return a tree of that type.\n",
      " |      :rtype: Tree\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  node\n",
      " |      Outdated method to access the node value; use the label() method instead.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __slotnames__ = []\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from builtins.list:\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __iadd__(self, value, /)\n",
      " |      Implement self+=value.\n",
      " |  \n",
      " |  __imul__(self, value, /)\n",
      " |      Implement self*=value.\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __reversed__(...)\n",
      " |      L.__reversed__() -- return a reverse iterator over the list\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      L.__sizeof__() -- size of L in memory, in bytes\n",
      " |  \n",
      " |  append(...)\n",
      " |      L.append(object) -> None -- append object to end\n",
      " |  \n",
      " |  clear(...)\n",
      " |      L.clear() -> None -- remove all items from L\n",
      " |  \n",
      " |  count(...)\n",
      " |      L.count(value) -> integer -- return number of occurrences of value\n",
      " |  \n",
      " |  extend(...)\n",
      " |      L.extend(iterable) -> None -- extend list by appending elements from the iterable\n",
      " |  \n",
      " |  index(...)\n",
      " |      L.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  insert(...)\n",
      " |      L.insert(index, object) -- insert object before index\n",
      " |  \n",
      " |  pop(...)\n",
      " |      L.pop([index]) -> item -- remove and return item at index (default last).\n",
      " |      Raises IndexError if list is empty or index is out of range.\n",
      " |  \n",
      " |  remove(...)\n",
      " |      L.remove(value) -> None -- remove first occurrence of value.\n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  reverse(...)\n",
      " |      L.reverse() -- reverse *IN PLACE*\n",
      " |  \n",
      " |  sort(...)\n",
      " |      L.sort(key=None, reverse=False) -> None -- stable sort *IN PLACE*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check the methods of a parse tree of nltk.tree.Tree type\n",
    "help(cnf_trees_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1j0ufc7guyUp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rules {NN -> 'board', VP -> PP NP, CD -> '29', S -> NP S, CD -> '61', NNS -> 'years', DT -> 'a', NP -> NNP NNP, PP -> IN NP, NP -> DT NN, IN -> 'as', NP -> ADJP ,, NP -> NNP CD, NNP -> 'nov.', NNP -> 'pierre', VP -> VB VP, NP -> DT NP, VP -> MD VP, MD -> 'will', JJ -> 'nonexecutive', NN -> 'director', , -> ',', ADJP -> NP JJ, NP -> NP NP, NNP -> 'vinken', JJ -> 'old', NP -> CD NNS, VB -> 'join', S -> VP ., NP -> JJ NN, . -> '.', DT -> 'the', NP -> , NP, VP -> NP VP} \n",
      "\n",
      "unique non-terminals {'PP', 'MD', 'NNP', ',', 'IN', 'DT', 'NNS', 'NN', 'JJ', 'VB', 'VP', 'NP', '.', 'S', 'CD', 'ADJP'} \n",
      "\n",
      "unique terminals {'join', ',', 'years', 'pierre', 'nonexecutive', 'old', 'as', 'nov.', '.', 'a', 'board', 'director', 'the', '61', 'vinken', 'will', '29'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "print (\"rules\", set(cnf_trees_train[0].productions()), '\\n')\n",
    "non_terminal_set = []\n",
    "for s in cnf_trees_train[0].subtrees(lambda t: t.height() >= 2):\n",
    "    non_terminal_set.append(s.label())\n",
    "print (\"unique non-terminals\", set(non_terminal_set), '\\n')\n",
    "print (\"unique terminals\", set(cnf_trees_train[0].leaves()), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zvrtosr-uyUq"
   },
   "source": [
    "There is an underlying PCFG used for parsing the sentences in the training set. To find out this PCFG, what we can do is to visit each parse tree that appears in the training set, and collect some useful information from each parse tree. Let us start with the following:\n",
    "- Obtain all the grammar rules, non-terminal symbols, and terminal symbols.\n",
    "- Show the numbers of unique non-terminal symbols, unique terminal symbols, and unique grammar rules. \n",
    "- List 10 most frequent grammar rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h9GWbp_duyUq"
   },
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "from collections import Counter\n",
    "\n",
    "terminal_counts = Counter()\n",
    "non_terminal_counts = Counter()\n",
    "grammar_rule_counts = Counter()\n",
    "\n",
    "for tree in cnf_trees_train:\n",
    "    for rule in tree.productions():\n",
    "        grammar_rule_counts[rule] += 1\n",
    "    for subtree in tree.subtrees(lambda t: t.height() >= 2):\n",
    "        non_terminal_counts[subtree.label()] += 1\n",
    "    for leaf in tree.leaves():\n",
    "        terminal_counts[leaf] += 1\n",
    "\n",
    "terminals = list(terminal_counts.keys())\n",
    "non_terminals = list(non_terminal_counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11226 74 14603\n",
      "[(PP -> IN NP, 6117), (, -> ',', 4758), (DT -> 'the', 4590), (NP -> DT NP, 3914), (. -> '.', 3715), (S -> VP ., 2971), (NP -> NP NP, 2813), (NP -> DT NN, 2813), (NP -> NP PP, 2592), (S -> NP S, 2507)]\n"
     ]
    }
   ],
   "source": [
    "print (len(terminals), len(non_terminals), len(grammar_rule_counts.keys()))\n",
    "print (grammar_rule_counts.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N5Bm_EcruyUs"
   },
   "source": [
    "Store the unique terminal and non-terminal symbols in two separate lists \"terminals\" and \"non-terminals\" respectively. Store the grammar rules and their respective counts in a dictionary \"grammar_rule_counts\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rOSlK0awuyUu"
   },
   "source": [
    "### Task 2 (8 points)\n",
    "\n",
    "We can estimate the parameters (i.e., probabilities for the grammar rules) based on the counts collected from the training set. \n",
    "- Show the estimated parameter (i.e., probability) for each of the following rules: $S \\rightarrow NP \\ VP$, $NP \\rightarrow DT \\ NN$, $DT \\rightarrow the$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EaqDZAZiuyUu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated probability for  S -> NP VP  =  0.09527165932452276\n",
      "estimated probability for  NP -> DT NN  =  0.07365995443714159\n",
      "estimated probability for  DT -> 'the'  =  0.5819703309243058\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "#The original keys are in a NLTK Terminal/Non-terminal/Production class\n",
    "non_terminal_counts_str = {str(k):v for k,v in non_terminal_counts.items()}\n",
    "grammar_rule_counts_str = {str(k):v for k,v in grammar_rule_counts.items()}\n",
    "\n",
    "for rules in [\"S -> NP VP\", \"NP -> DT NN\", \"DT -> 'the'\"]:\n",
    "    print(\"estimated probability for \", rules, \" = \", grammar_rule_counts_str[rules]/non_terminal_counts_str[rules.split(' ->')[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zWTpGd8FuyUw"
   },
   "source": [
    "It is possible that some sentences cannot be parsed under the PCFG learned from a limited training set. Take \"Fruit flies like a banana\" for example, assume its PCFG is:\n",
    "\n",
    "$S → NP \\ S \\ (1)$\n",
    "\n",
    "$NP → A \\ N \\ (0.5)$\n",
    "\n",
    "$VP → V \\ NP \\ (1)$\n",
    "\n",
    "$NP → D \\ N \\ (0.5)$\n",
    "\n",
    "$A → Fruit \\ (1)$\n",
    "\n",
    "$N → flies \\ (0.5)$\n",
    "\n",
    "$V → like \\ (1)$\n",
    "\n",
    "$D→ a \\ (1)$\n",
    "\n",
    "$N → banana \\ (0.5)$\n",
    "\n",
    "In this case, we cannot construct a tree because there is no rule that can connect $S$ to $VP$.\n",
    "\n",
    "Now, consider another PCFG as follows:\n",
    "\n",
    "$S → NP \\ VP \\ (1)$\n",
    "\n",
    "$NP → A \\ N \\ (0.5)$\n",
    "\n",
    "$VP → V \\ NP \\ (1)$\n",
    "\n",
    "$NP → D \\ N \\ (0.5)$\n",
    "\n",
    "$A → Fruit \\ (1)$\n",
    "\n",
    "$N → flies \\ (0.5)$\n",
    "\n",
    "$V → like \\ (1)$\n",
    "\n",
    "$D→ the \\ (1)$\n",
    "\n",
    "$N → banana \\ (0.5)$\n",
    "\n",
    "In this case, we still cannot construct a tree because there is no rule for the terminal symbol \"a\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jxuhx5vLuyUw"
   },
   "source": [
    "Let us do a simple check on one test sentence:\n",
    "- Find out all terminal symbols of cnf_trees_test[0] that never appear in the PCFG rules that we have learned from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rSRRo6-9uyUw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen terminal symbol  300-day\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "for terminal in cnf_trees_test[0].leaves():\n",
    "    if terminal_counts[terminal] == 0:\n",
    "        print (\"Unseen terminal symbol \",terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bpKhV3LUuyUy"
   },
   "source": [
    "We can use smoothing techniques to handle these cases. A simple smoothing method is as follows. We first create a new \"unknown\" non-terminal symbol $UNK$ and a new \"unknown\" terminal symbol $unk$.\n",
    "\n",
    "Next, for each original non-terminal symbol $A\\in N$, we add two new rules $A \\rightarrow UNK \\ UNK$ and $A \\rightarrow unk$ to the original PCFG.\n",
    "\n",
    "For each terminal symbol $\\alpha \\in \\Sigma$, we add one new rule $UNK \\rightarrow \\alpha$ to the original PCFG.\n",
    "\n",
    "The smoothed probabilities for all rules can then be estimated as:\n",
    "$$q_{smooth}(A \\rightarrow \\beta) = \\frac {count(A \\rightarrow \\beta)}{count(A)+2}$$\n",
    "$$q_{smooth}(A \\rightarrow UNK \\ UNK) = \\frac {1}{count(A)+2}$$\n",
    "$$q_{smooth}(A \\rightarrow unk) = \\frac {1}{count(A)+2}$$\n",
    "$$q_{smooth}(UNK \\rightarrow \\alpha) = \\frac {1}{|V|}$$\n",
    "where $|V|$ is the count of unique terminal symbols, and the values of $count(\\cdot)$ are the same as the ones used in Task 1 above.\n",
    "\n",
    "- Add \"$UNK$\", \"$unk$\" to the two lists \"non_terminals\" and \"terminals\" respectively, compute and store the smoothed probabilities of grammar rules in a Python dictionary \"smoothed_grammar_rule_probs\". \n",
    "- Show the smoothed probability for each of the following rules: \n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ S \\rightarrow NP \\ VP$\n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ NP \\rightarrow DT  \\ NN$\n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ DT \\rightarrow the$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcX_zy5juyUy"
   },
   "outputs": [],
   "source": [
    "#Write your code to update the PCFG\n",
    "from nltk.grammar import  Nonterminal\n",
    "terminals.append('unk')\n",
    "non_terminals.append(Nonterminal('UNK'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.grammar import  Production\n",
    "\n",
    "# +1 for each non_terminal and terminal first, we will iterate through this later\n",
    "for non_terminal in non_terminals:\n",
    "    if str(non_terminal) != 'UNK':\n",
    "        grammar_rule_counts[Production(non_terminal, [Nonterminal('UNK'), Nonterminal('UNK')])] += 1\n",
    "        grammar_rule_counts[Production(non_terminal, ['unk'])] += 1\n",
    "for terminal in terminals:\n",
    "    if terminal != 'unk':\n",
    "        grammar_rule_counts[Production(Nonterminal('UNK'), [terminal])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25977\n",
      "14603\n"
     ]
    }
   ],
   "source": [
    "print (len(grammar_rule_counts.keys()))\n",
    "# difference of 1 is due to 'unk' and 'UNK' being added to the 2 list\n",
    "print (len(grammar_rule_counts.keys()) - (len(terminals)-1) -  2*(len(non_terminals)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAoEIyuOuyUz"
   },
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "smoothed_grammar_rule_probs = {}\n",
    "for rule, count in grammar_rule_counts.items():\n",
    "    if str(rule.lhs()) == 'UNK':\n",
    "        smoothed_grammar_rule_probs[rule] = count/len(terminals)\n",
    "    else:\n",
    "        smoothed_grammar_rule_probs[rule] = count/(non_terminal_counts[str(rule.lhs())]+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated probability for  S -> NP VP  =  0.09526046866741059\n",
      "estimated probability for  NP -> DT NN  =  0.07365609698620093\n",
      "estimated probability for  DT -> 'the'  =  0.5818227912282926\n"
     ]
    }
   ],
   "source": [
    "smoothed_grammar_rule_probs_str = {str(k):v for k,v in smoothed_grammar_rule_probs.items()}\n",
    "\n",
    "for rules in [\"S -> NP VP\", \"NP -> DT NN\", \"DT -> 'the'\"]:\n",
    "    print(\"estimated probability for \", rules, \" = \", smoothed_grammar_rule_probs_str[rules])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "A2iy5GQeuyU1"
   },
   "source": [
    "## CKY Algorithm\n",
    "\n",
    "### Task 3 (10 points)\n",
    "Similar to the Viterbi algorithm, the CKY algorithm is a dynamic-programming algorithm. Given a PCFG $G=(N, \\ \\Sigma, \\ S, \\ R, \\ q)$, we can use the CKY algorithm described in class to find the highest scoring parse tree for a sentence. \n",
    "\n",
    "First, let us complete the *CKY* function from scratch using only Python built-in functions and the Numpy package. \n",
    "\n",
    "The output should be two dictionaries $\\pi$ and $bp$, which store the optimal probability and backpointer information respectively.\n",
    "\n",
    "Given a sentence $w_0, w_1, ...,w_{n-1}$,  $\\pi(i, k, X)$, $bp(i, k, X)$ refer to the highest score and backpointer for the (partial) parse tree that has the root X (a non-terminal symbol) and covers the word span $w_i, ..., w_{k-1}$, where $0 \\le i < k \\le n$. Note that a backpointer includes both the best grammar rule chosen and the best split point.\n",
    "![tree](imgs/parse_tree.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KyHlRk1AuyU1"
   },
   "source": [
    "Take \"Fruit flies like a banana\" for example, $\\pi(0, 5, S)$ is the probability of the optimal complete parse tree, $bp(0, 5, S)$ is the corresponding backpointer. Specifically, the best split point is 2 and the best grammar rule chosen is $S \\rightarrow NP \\ VP$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxiCymv-uyU1"
   },
   "outputs": [],
   "source": [
    "def CKY(sent, non_terminals, terminals, grammar_rule_probs):\n",
    "    \n",
    "    '''\n",
    "    CKY algorithm\n",
    "    args:\n",
    "        sent: a sequence of words, list\n",
    "        non_terminals: non-terminal symbols, list\n",
    "        terminals: terminal symbols, list\n",
    "        grammar_rule_probs: probabilities of the rules, dictionary\n",
    "    returns:\n",
    "        pi: highest score for (partial) parse tree, dictionary\n",
    "        bp: backpointers, dictionary\n",
    "    '''\n",
    "    pi, bp ={}, {}\n",
    "    n = len(sent)\n",
    "    \n",
    "    #from leaves to tree\n",
    "    for level in range(1, n+1):\n",
    "        #base case\n",
    "        if level == 1: \n",
    "\n",
    "            # iterate through terminal tokens\n",
    "            for pos, token in enumerate(sent):\n",
    "\n",
    "                # best prob for each LHS at per-terminal level\n",
    "                best_prob = Counter()\n",
    "                \n",
    "                # iterate through rules\n",
    "                for rule, prob in grammar_rule_probs.items():\n",
    "                    lhs, rhs = rule.lhs(), rule.rhs()\n",
    "                    # for some ridiculous reason, some nonterminals are turned to string\n",
    "                    if type(lhs) is str:\n",
    "                        lhs = Nonterminal(lhs)\n",
    "                    if rhs[0] == token:\n",
    "                        pi[(pos, pos+1, lhs)] = prob\n",
    "                        if prob >= best_prob[lhs]:\n",
    "                            bp[(pos, pos+1, lhs)] = (rule, None)\n",
    "        \n",
    "        # recursive definition\n",
    "        else:\n",
    "            \n",
    "            # iterate through (n - level + 1) partial trees\n",
    "            for pos in range(n - level + 1):\n",
    "                \n",
    "                # best prob for each LHS at this level\n",
    "                best_prob = Counter()\n",
    "                    \n",
    "                # iterate through (level - 1) split points\n",
    "                for split in range(1, level):\n",
    "                    \n",
    "                    # iterate through rules\n",
    "                    for rule, prob in grammar_rule_probs.items():\n",
    "                        lhs, rhs = rule.lhs(), rule.rhs()\n",
    "                        # for some ridiculous reason, some nonterminals are turned to string\n",
    "                        if type(lhs) is str:\n",
    "                            lhs = Nonterminal(lhs)\n",
    "                        # only look at production rules that are not pre-terminal\n",
    "                        if len(rhs) > 1:\n",
    "                            if (pos, pos+split, rhs[0]) in pi and (pos+split, pos+level, rhs[1]) in pi:\n",
    "                                prob = pi[(pos, pos+split, rhs[0])] * pi[(pos+split, pos+level, rhs[1])]\n",
    "                                pi[(pos, pos+level, lhs)] = prob\n",
    "                                if prob >= best_prob[lhs]:\n",
    "                                    bp[(pos, pos+level, lhs)] = (rule, split)\n",
    "\n",
    "    #Complete the code\n",
    "    return pi, bp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mjZ2j-fduyU2"
   },
   "source": [
    "Let us complete the *generate_parse_tree* function that can return a tree based on two arguments -- backpointers $bp$ and a \"start node\" $start$, where the \"start node\" is a tuple consisting of a span and a non-terminal symbol that covers that span. For example, if we set the start node as $(0, 5, S)$, the function will recursively build a tree based on the infomration stored in $bp$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTSw4F5XuyU3"
   },
   "outputs": [],
   "source": [
    "def generate_parse_tree(bp, start):\n",
    "    '''\n",
    "    Recursively construct a tree\n",
    "    args:\n",
    "        bp: backpointers that allow us to recover the highest scoring parse tree, dictionary\n",
    "        start: the start node, i.e., (i, k, X), which refers to the non-terminal root X and the words span [i, k) it covers, tuple\n",
    "    return:\n",
    "        tree: the parse tree, nltk.tree.Tree type\n",
    "    '''\n",
    "    \n",
    "    rule, split = bp[(start[0], start[1], start[2])]\n",
    "    if split:\n",
    "        left_child_start = (start[0], start[0] + split, rule.rhs()[0])\n",
    "        right_child_start = (start[0] + split, start[1], rule.rhs()[1])\n",
    "        return nltk.tree.Tree(start[2], [generate_parse_tree(bp, left_child_start), generate_parse_tree(bp, right_child_start)])\n",
    "    else:\n",
    "        return nltk.tree.Tree(start[2], rule.rhs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VgNAZFUGuyU4"
   },
   "source": [
    "Now using the PCFG learned from Task 2, we can work on the following:\n",
    "- Compute the max probability for the sentence \"the boy saw a nice cat\" based on \"terminals\", \"non_terminals\", \"smoothed_rule_probs\" obtained in Task 2.\n",
    "- Generate and display the parse tree of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73e_mqx5uyU4"
   },
   "outputs": [],
   "source": [
    "sent = \"the boy saw a nice cat\".split()\n",
    "pi, bp = CKY(sent, non_terminals, terminals, smoothed_grammar_rule_probs)\n",
    "tree =  generate_parse_tree(bp, (0, len(sent), Nonterminal('S')))\n",
    "#Write your code to display max probability and generate the parse tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (ADJP (JJ the) (RB (UNK boy) (UNK saw))) (NN a))\n",
      "  (UCP (UNK nice) (UNK cat)))\n"
     ]
    }
   ],
   "source": [
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8WLdpSaxuyU5"
   },
   "source": [
    "## Evaluate Our Parser\n",
    "\n",
    "Now we can use the CKY algorithm implemented in Task 3 to predict parse trees on sentences from the test set, then evaluate the performance based on the gold parse trees of the test set. Before we perform the evaluation, we need to represent our parse trees in a form of constituents which are denoted as brackets $X(i, j)$, where $X$ is the non-terminal symbol **that has two children**, and $i$, $j$ refers to the starting point (inclusive) and ending point (exclusive) respectively. **(In other words, a constituent cannot consist of a single word only.)**\n",
    "\n",
    "Metrics are defined as:\n",
    "- Precision = (# of correct constituents in the predicted parse trees)/(# of total constituents in the predicted parse trees)\n",
    "\n",
    "- Recall = (# of correct constituents in the predicted parse trees)/(# of correct constituents in the gold parse trees)\n",
    "\n",
    "- F1 score = 2\\*precision\\*recall/(precision+recall)\n",
    "\n",
    "Using the sentence \"Fruit flies like a banana\" as example again, there are five words in the sentence with labels from 0 to 4. Assume the constituents are $S(0, 5)$, $NP(0, 2)$, $VP(2, 5)$, $NP(3, 5)$ in the gold parse tree (shown in Task 3), and $S(0, 5)$, $NP(0, 2)$, $PP(2, 5)$, $NP(3, 5)$ in the predicted parse tree (shown below). Then the precision = 3/4, the recall = 3/4, and the F1 score = 0.75. \n",
    "![parse_tree](imgs/parse_tree2.png)\n",
    "\n",
    "### Task 4 (6 points):\n",
    "- Run the CKY algorithm on the test set and generate parse trees under the smoothed PCFG obtained in Task 2. Note that some test sentences contain words that are not included in the  list \"terminals\", set those words as $unk$.\n",
    "- Extract the constituents from the gold and predicted parse trees respectively.\n",
    "- Compute the overall precision, recall and F1 score for the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IKYB639xuyU5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 24/24\r"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "from collections import deque\n",
    "gold_const = 0\n",
    "pred_const = 0\n",
    "corr_pred = 0\n",
    "total = len(cnf_trees_test)\n",
    "\n",
    "for idx, tree in enumerate(cnf_trees_test):\n",
    "    print (\"Evaluating %d/%d\" %(idx +1 , total), end=\"\\r\")\n",
    "    sent = [token if token in terminals else 'unk' for token in tree.leaves()]\n",
    "    pi, bp = CKY(sent, non_terminals, terminals, smoothed_grammar_rule_probs)\n",
    "    pred_tree =  generate_parse_tree(bp, (0, len(sent), Nonterminal('S')))\n",
    "    gold_subtree_list = deque([(tree, 0, len(sent))])\n",
    "    gold_const_list = []\n",
    "    gold_const_list.append((Nonterminal('S'), 0, len(sent)))\n",
    "    \n",
    "    # queue system to go through subtrees\n",
    "    while len(gold_subtree_list) > 0:\n",
    "        gold_subtree, start, end = gold_subtree_list.popleft()\n",
    "        left_child = gold_subtree[0]\n",
    "        right_child = gold_subtree[1]\n",
    "        split = start + len(left_child.leaves())\n",
    "        \n",
    "        if left_child.height() > 2:\n",
    "            gold_const_list.append((left_child.label(), start, split))\n",
    "            gold_subtree_list.append((left_child, start, split))\n",
    "        if right_child.height() > 2:\n",
    "            gold_const_list.append((right_child.label(), split, end))\n",
    "            gold_subtree_list.append((right_child, split, end))\n",
    "            \n",
    "    pred_subtree_list = deque([(pred_tree, 0, len(sent))])\n",
    "    pred_const_list = []\n",
    "    pred_const_list.append((Nonterminal('S'), 0, len(sent)))\n",
    "    \n",
    "    # queue system to go through subtrees\n",
    "    while len(pred_subtree_list) > 0:\n",
    "        pred_subtree, start, end = pred_subtree_list.popleft()\n",
    "        left_child = pred_subtree[0]\n",
    "        right_child = pred_subtree[1]\n",
    "        split = start + len(left_child.leaves())\n",
    "        \n",
    "        if left_child.height() > 2:\n",
    "            pred_const_list.append((left_child.label(), start, split))\n",
    "            pred_subtree_list.append((left_child, start, split))\n",
    "        if right_child.height() > 2:\n",
    "            pred_const_list.append((right_child.label(), split, end))\n",
    "            pred_subtree_list.append((right_child, split, end))\n",
    "    \n",
    "    \n",
    "    for const in pred_const_list:\n",
    "        if const in gold_const_list:\n",
    "            corr_pred += 1\n",
    "    gold_const += len(gold_const_list)\n",
    "    pred_const += len(pred_const_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05150214592274678"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = corr_pred/gold_const\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05150214592274678"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = corr_pred/pred_const\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05150214592274678"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = 2*precision*recall/(precision + recall)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework 2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
